{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9cf395f",
   "metadata": {},
   "source": [
    "### **Dataset Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fff5fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127dddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATASET\n",
    "df = pd.read_csv(\"drug_consumption.csv\")\n",
    "# Remove records claiming use of \"Semeron\" (fake drug to identify drug seekers)\n",
    "df = df[df['semer'] == 'CL0']\n",
    "feature_file_dict = {f\"{feat}\":f\"additional-variable-information/{i}-{feat}.csv\" for i,feat in enumerate(df.columns.to_list())}\n",
    "# Create dataframes to separate input & target features \n",
    "input_features = ['age','gender', 'education', 'country', 'ethnicity',\n",
    "    'n_score', 'e_score', 'o_score', 'a_score', 'c_score', \n",
    "    'impulsive_bis11', 'sensation_seeking_impss']\n",
    "target_features = ['alcohol', 'amphet', 'amyl', 'benzos', 'caff', 'cannabis', \n",
    "    'choc', 'coke', 'crack', 'ecstasy', 'heroin', 'ketamine', 'legalh', 'lsd', \n",
    "    'meth', 'mushrooms', 'nicotine', 'vsa']\n",
    "df_input = df[input_features].copy()\n",
    "df_target = df[target_features].copy()\n",
    "df_input = df_input.set_index(df['recordID'])\n",
    "df_target = df_target.set_index(df['recordID'])\n",
    "scaler = StandardScaler() # to normalize data for NN training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23874172",
   "metadata": {},
   "source": [
    "#### **Input Features:** Demographic & Personality Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bacfc164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP FEATURES INTO INPUT VARIABLE TYPES\n",
    "\n",
    "# Separate variables by grouping psychometric scores and classify categorical features by ordinal/nominal data dichotomy\n",
    "ordinal_inputs = ['age', 'education']\n",
    "nominal_inputs = ['gender', 'country', 'ethnicity']\n",
    "scored_inputs = ['n_score', 'e_score', 'o_score', 'a_score', 'c_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8280550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT INPUT FEATURE VALUES TO MEANINGS (FOR READABILITY)\n",
    "\n",
    "# Convert input_df feature values with each variable value's corresponding meaning\n",
    "for var_dem in ordinal_inputs+nominal_inputs:\n",
    "    df_var = pd.read_csv(feature_file_dict[var_dem], usecols=['Value', 'Meaning'])\n",
    "    value_meanings = pd.Series(df_var['Meaning'].values, index=df_var['Value']).to_dict()\n",
    "    df_input[var_dem] = df_input[var_dem].map(value_meanings)\n",
    "for score in scored_inputs:\n",
    "    score_col = f\"{score[0].capitalize()}score\"\n",
    "    df_score = pd.read_csv(feature_file_dict[score], usecols=[score_col, 'Value'])\n",
    "    value_scores = pd.Series(df_score[score_col].values, index=df_score['Value']).to_dict()\n",
    "    df_input[score] = df_input[score].map(value_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e27168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE & SCALE INPUT FEATURES\n",
    "\n",
    "# Use sklearn's OrdinalEncoder for ordinal input features\n",
    "ordinal_categories = [\n",
    "    ['18-24', '25-34', '35-44', '45-54', '55-64', '65+'],  # Age order\n",
    "    ['Left school before 16 years', 'Left school at 16 years', 'Left school at 17 years',\n",
    "     'Left school at 18 years', 'Some college/university without certificate/degree',\n",
    "     'Professional certificate/diploma', 'University degree', 'Masters degree', 'Doctorate degree']  # Education order\n",
    "]\n",
    "ordinal_encoder = OrdinalEncoder(categories=ordinal_categories)\n",
    "df_input[ordinal_inputs] = ordinal_encoder.fit_transform(df_input[ordinal_inputs])\n",
    "# Use one-hot encoding for nominal input features\n",
    "df_input = pd.get_dummies(df_input, columns=nominal_inputs)\n",
    "# Standardize psychometric scores by CENTERING and SCALING (mean=0, std=1)\n",
    "df_input[scored_inputs+['impulsive_bis11', 'sensation_seeking_impss']] = scaler.fit_transform(df_input[scored_inputs+['impulsive_bis11', 'sensation_seeking_impss']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090b5f1",
   "metadata": {},
   "source": [
    "#### **Target Features:** Drug/Substance Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69aa3e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUPING FEATURES INTO DRUG GROUPS \n",
    "\n",
    "# Using The Drugs Wheel (UK & Ireland DrugWatch) @ https://www.thedrugswheel.com/\n",
    "dissociatives = ['ketamine']\n",
    "depressants = ['alcohol', 'benzos']\n",
    "opioids = ['heroin', 'meth']\n",
    "cannabinoids = ['cannabis']\n",
    "stimulants = ['amphet', 'coke', 'crack', 'nicotine']\n",
    "empathogens = ['ecstasy']\n",
    "psychedelics = ['lsd', 'mushrooms']\n",
    "# Made a group to include VSA & Amyl Nitrate\n",
    "inhalants = ['amyl', 'vsa']\n",
    "# NOTE: Chose to exclude the Chocolate & Legal Highs variables on basis of relevance, \n",
    "#       as team goal is to predict illegal/heavily regulated substance use for harm reduction planning/diagnostics\n",
    "# NOTE: Removed Caffeine on the basis of not being a illegal nor heavily regulated substance. \n",
    "#         While it DOES have effects of a stimulant, its use shouldn't be conflated with stimulants like Amphetamines or Cocaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5a285f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAP VALUES (EMPHASIZING RECENCY) TO DATASET \n",
    "\n",
    "# Using NON-LINEAR (exponential) scale to emphasize recency -> more relevant to harm reduction \n",
    "# (rather than focusing on past/experimental use) \n",
    "recency_map = {f'CL{i}': 2**i for i in range(7)}\n",
    "# DataFrame to store weighted 'use' values and map scale to drug features, to be used in PCA \n",
    "weighted_consumption = pd.DataFrame()\n",
    "drugs = dissociatives + depressants + opioids + cannabinoids + stimulants + empathogens + psychedelics + inhalants\n",
    "for drug in drugs:\n",
    "    weighted_consumption[f\"{drug}\"] = df_target[drug].map(recency_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a79b2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINCIPAL COMPONENT ANALYSIS\n",
    "\n",
    "# Use PCA to reduce dimensionality by 'collapsing' drugs in the same group into a single feature\n",
    "pca_groups = { # groups with more than one feature\n",
    "    'depressants': depressants,\n",
    "    'opioids': opioids,\n",
    "    'stimulants': stimulants,\n",
    "    'psychedelics': psychedelics,\n",
    "    'inhalants': inhalants\n",
    "}\n",
    "for name, group in pca_groups.items():\n",
    "    group_features = weighted_consumption[group]\n",
    "    pca = PCA(n_components=1)\n",
    "    df_target[f'{name}_pca'] = pca.fit_transform(group_features)\n",
    "# Copy over the values from groups with only ONE feature\n",
    "df_target['dissociatives'] = weighted_consumption['ketamine']\n",
    "df_target['cannabinoids'] = weighted_consumption['cannabis']\n",
    "df_target['empathogens'] = weighted_consumption['ecstasy']\n",
    "# Standardize values across drug groups, including both PCA and single-drug ones\n",
    "new_features = ['dissociatives', 'cannabinoids', 'empathogens', 'depressants_pca', 'opioids_pca', 'stimulants_pca', 'psychedelics_pca', 'inhalants_pca']\n",
    "# New drug features are CENTERED and SCALED (mean=0, std=1), to train Neural Networks\n",
    "df_target[new_features] = scaler.fit_transform(df_target[new_features])\n",
    "# Remove pre-grouped drug features\n",
    "df_target = df_target.drop(target_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf9b688",
   "metadata": {},
   "source": [
    "#### **Save Processed Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f50a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECOMBINE INPUTS & TARGETS\n",
    "\n",
    "df_processed = pd.concat([df_input, df_target], axis=1)\n",
    "df_processed.to_csv(\"processed_drug_consumption.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-3001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
