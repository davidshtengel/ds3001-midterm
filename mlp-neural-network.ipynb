{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d015841",
   "metadata": {},
   "source": [
    "### **Multi-Layer Perceptron (MLP) Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f1e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from tqdm.notebook import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9d2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD PROCESSED DATA\n",
    "df = pd.read_csv(\"processed_drug_consumption.csv\")\n",
    "# Specify input & target columns\n",
    "target_cols = [\n",
    "    'dissociatives', 'cannabinoids', 'empathogens',\n",
    "    'depressants_pca', 'opioids_pca', 'stimulants_pca', 'psychedelics_pca', 'inhalants_pca'\n",
    "]\n",
    "input_cols = [col for col in df.columns if col not in target_cols] # there're FAR more input columns after one-hot encoding nominal variables\n",
    "\n",
    "X = df[input_cols].values.astype('float32')\n",
    "y = df[target_cols].values.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2150a",
   "metadata": {},
   "source": [
    "#### **Prepare Data for PyTorch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43333fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRANSFORM DATA FOR PYTORCH\n",
    "\n",
    "# Convert numpy representation of dataframes into compatible, multi-dimensional arrays (which can run on either CPU or GPU!)\n",
    "X_tensor = torch.tensor(X)\n",
    "y_tensor = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48ca4f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE PYTORCH DATALOADER\n",
    "\n",
    "# Make PyTorch TensorDataset to be passed to the DataLoader\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "# Specify train/test dataset sizes (80/20 split), and split the dataset into two aforementioned datasets\n",
    "train_size = int(0.80 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, lengths=[train_size, test_size])\n",
    "\n",
    "# Create PyTorch DataLoaders to \"simplify loading and iterating over datasets while training deep learning models\" https://www.geeksforgeeks.org/deep-learning/pytorch-dataloader/ \n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True) # Add shuffling to training data to prevent model from \"memorizing\" data order and finding unreliable/dubious patterns (not needed when testing)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32) # 32 is common batch size for smaller datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f7401a",
   "metadata": {},
   "source": [
    "#### **Build/Configure Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94b4c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD MLP MODEL\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    # Model initialization with number of input/output features and (opt.) number of neurons in the hidden layers\n",
    "    def __init__(self, input_size, output_size, hidden_neurons=64):\n",
    "        super().__init__() # initializes parent class\n",
    "        # Make the fully-connected/dense layers (having only one layer would make a linear model)\n",
    "        self.fc1 = nn.Linear(input_size, hidden_neurons) # Input\n",
    "        self.fc2 = nn.Linear(hidden_neurons, hidden_neurons)\n",
    "        self.fc3 = nn.Linear(hidden_neurons, output_size) # Output\n",
    "    # Setup forward passing (data flow through the network)\n",
    "    def forward(self, x):\n",
    "        # Pass through the layers and apply ReLU activation (popular activation function, also add \"non-linearity\") after hidden layers (where app.) \n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "model = MLP(input_size=X.shape[1], output_size=y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c313621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SETUP LOSS FUNCTION & OPTIMIZER\n",
    "\n",
    "# Setup optimizer (Adam is commonly used, it adapts learning rate per parameter from model.parameters())\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# Use Mean Squared Error for the loss function (default for most regression problems)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4a9ab",
   "metadata": {},
   "source": [
    "#### **Train & Evalute the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de845bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986dcf4abd22498f8b0b7f832aaf56bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAIN MODEL\n",
    "\n",
    "# Loop through epochs, training the model X times with the training data (higher X, more learning -> too high X, overfitting)\n",
    "epochs = 50\n",
    "progress_bar = trange(epochs, desc=\"Training\", dynamic_ncols=True)\n",
    "for epoch in progress_bar:\n",
    "    # Sets model in training mode and create accumulator for epoch's total loss \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_samples = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad() # Reset gradient values (prevent unwanted accumulation)\n",
    "        predictions = model(batch_X) # Forward pass to get predictions\n",
    "        # Calculate loss and backpropogate (calculate loss gradients w.r.t. model parameters)\n",
    "        loss = criterion(predictions, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step() # Update weights w/ Adam (optimizer algorithm)\n",
    "        batch_size = batch_X.size(0)\n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "        total_samples += batch_size\n",
    "    avg_loss = running_loss / total_samples\n",
    "    progress_bar.set_postfix(epoch=epoch+1, avg_loss=f\"{avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b283d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE (overall): 0.9835370779037476\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE MODEL\n",
    "\n",
    "# Sets model in evalation mode\n",
    "model.eval()\n",
    "with torch.no_grad():   # turn off gradient computation, unnecessary and saves memory\n",
    "    # Prepare lists to store each batch's predictions and the true values \n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    for batch_X, batch_y in test_loader: # iterates and appends through test data\n",
    "        preds = model(batch_X)\n",
    "        all_preds.append(preds.numpy())\n",
    "        all_targets.append(batch_y.numpy())\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_targets = np.vstack(all_targets)\n",
    "# Calculate overall root mean squared error (standard regression metric) \n",
    "rmse = root_mean_squared_error(all_targets, all_preds)\n",
    "print(\"Test RMSE (overall):\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9944829c",
   "metadata": {},
   "source": [
    "#### **Save Model Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66aa2011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights saved!\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"mlp_drug_predictor.pth\")\n",
    "print(\"Model weights saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-3001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
